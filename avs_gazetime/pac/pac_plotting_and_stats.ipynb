{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase-Amplitude Coupling (PAC) Source Analysis for MEG Data\n",
    "\n",
    "This notebook performs source-level PAC analysis on MEG data for saccade events.\n",
    "\n",
    "## Analysis workflow:\n",
    "1. **Data Loading**: Load source estimates and PAC results\n",
    "2. **Morphing**: Transform individual data to fsaverage space\n",
    "3. **ROI Analysis**: Extract PAC values for regions of interest\n",
    "4. **Statistical Analysis**: Test significance across brain regions\n",
    "5. **Visualisation**: Create brain plots and statistical summaries\n",
    "\n",
    "**Author**: [Your Name]  \n",
    "**Date**: [Date]  \n",
    "**Analysis**: Theta-gamma PAC during saccade events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import mne\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib import colors as mcolors\n",
    "\n",
    "# Configure plotting\n",
    "sns.set_context(\"poster\")\n",
    "color_peak = \"#de5733ff\"\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject and data configuration\n",
    "subjects = [1, 2, 3, 4, 5]\n",
    "event_types = ['saccade']\n",
    "method = \"beamformer\"\n",
    "surrogate_method = \"single_cut\"\n",
    "\n",
    "# Frequency bands\n",
    "theta_freqs = (3, 8)\n",
    "gamma_freqs = (40, 140)\n",
    "\n",
    "# Time window for PAC analysis\n",
    "time_window = [0.15, 0.4]\n",
    "\n",
    "# Data paths\n",
    "SUBJECTS_DIR = \"/Users/atlas/avs/rawdir/\"\n",
    "avs_dir = \"/Users/atlas/avs\"\n",
    "data_dir = \"/Users/atlas/share_psulewski/psulewski/active-visual-semantics-MEG/results/fullrun/analysis/gazetime/submission_checks/ica/stc/filter_0.2_200/\"\n",
    "\n",
    "print(f\"Analysis configuration:\")\n",
    "print(f\"- Subjects: {subjects}\")\n",
    "print(f\"- Theta band: {theta_freqs[0]}-{theta_freqs[1]} Hz\")\n",
    "print(f\"- Gamma band: {gamma_freqs[0]}-{gamma_freqs[1]} Hz\")\n",
    "print(f\"- Time window: {time_window[0]}-{time_window[1]} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI Definitions\n",
    "\n",
    "Define anatomical regions of interest based on the Glasser atlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compound ROI labels for analysis\n",
    "compound_labels = {\n",
    "    \"early\": [\"early\"],  # Early visual cortex\n",
    "    \"parietal\": [\"midparietal\", \"parietal\"],\n",
    "    \"lateral\": [\"midlateral\", \"lateral\"],  # Lateral visual cortex\n",
    "    \"ventral\": [\"midventral\", \"ventral\"],  # Ventral visual cortex\n",
    "    \"HC\": [\"H\"],  # Hippocampus\n",
    "    \"EC\": [\"EC\"],  # Entorhinal cortex\n",
    "    \"FEF\": [\"FEF\"],  # Frontal eye fields\n",
    "    \"dlPFC\": [\"8C\", \"8Av\", \"i6-8\", \"s6-8\", \"SFL\", \"8BL\", \"9p\", \"9a\", \"8Ad\", \n",
    "              \"p9-46v\", \"a9-46v\", \"46\", \"9-46d\"],  # Dorsolateral prefrontal cortex\n",
    "    \"OFC\": [\"47s\", \"47m\", \"a47r\", \"11l\", \"13l\", \"a10p\", \"p10p\", \"10pp\", \n",
    "            \"10d\", \"OFC\", \"pOFC\"],  # Orbitofrontal cortex\n",
    "    \"infFC\": [\"45\", \"IFJp\", \"IFJa\", \"IFSp\", \"IFSa\", \"47l\", \"p47r\"],  # Inferior frontal cortex\n",
    "    \"mPFC\": [\"33pr\", \"p24pr\", \"a24pr\", \"p24\", \"a24\", \"p32pr\", \"a32pr\", \n",
    "             \"d32\", \"p32\", \"s32\", \"8BM\", \"9m\", \"10v\", \"10r\", \"25\"]  # Medial prefrontal cortex\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(compound_labels)} ROI categories:\")\n",
    "for roi, labels in compound_labels.items():\n",
    "    print(f\"- {roi}: {len(labels)} sub-regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject, event_type, data_dir, avs_dir):\n",
    "    \"\"\"\n",
    "    Load source estimate and PAC results for a single subject.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subject : int\n",
    "        Subject number\n",
    "    event_type : str\n",
    "        Event type (e.g., 'saccade')\n",
    "    data_dir : str\n",
    "        Path to PAC results directory\n",
    "    avs_dir : str\n",
    "        Path to source estimates directory\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stc : mne.SourceEstimate\n",
    "        Source estimate object\n",
    "    pac_results : pd.DataFrame\n",
    "        PAC results dataframe\n",
    "    \"\"\"\n",
    "    sub_name = f\"as{subject:02d}\"\n",
    "    \n",
    "    # Load source estimate\n",
    "    stc_fname = (f\"{avs_dir}/population_codes/{sub_name}/source_space/{method}/\"\n",
    "                f\"glasser/ori_normal/hem_both/filter_0.2_200/ica/{sub_name}a_stcs_{event_type}\")\n",
    "    stc = mne.read_source_estimate(stc_fname)\n",
    "    \n",
    "    # Load PAC results\n",
    "    pac_results_fname = (f\"pac_results_{subject}_stc_{event_type}_\"\n",
    "                        f\"{theta_freqs[0]}-{theta_freqs[1]}_\"\n",
    "                        f\"{gamma_freqs[0]}-{gamma_freqs[1]}_\"\n",
    "                        f\"{time_window[0]}-{time_window[1]}_{surrogate_method}.csv\")\n",
    "    \n",
    "    pac_results = pd.read_csv(os.path.join(data_dir, sub_name, pac_results_fname))\n",
    "    \n",
    "    print(f\"Loaded data for {sub_name}: {len(pac_results)} PAC values\")\n",
    "    \n",
    "    return stc, pac_results\n",
    "\n",
    "\n",
    "def create_pac_stc(stc, pac_results):\n",
    "    \"\"\"\n",
    "    Create source estimate with PAC values as data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stc : mne.SourceEstimate\n",
    "        Template source estimate\n",
    "    pac_results : pd.DataFrame\n",
    "        PAC results with 'channel' and 'pac' columns\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pac_stc : mne.SourceEstimate\n",
    "        Source estimate with PAC values\n",
    "    \"\"\"\n",
    "    pac_stc = stc.copy()\n",
    "    \n",
    "    # Remove duplicates (keep last value)\n",
    "    pac_results_clean = pac_results.sort_values(by=\"channel\")\n",
    "    pac_results_clean = pac_results_clean.drop_duplicates(subset=\"channel\", keep=\"last\")\n",
    "    pac_results_clean = pac_results_clean.set_index(\"channel\")\n",
    "    \n",
    "    # Prepare PAC data array\n",
    "    pac_data = np.full((pac_stc.data.shape[0], 1), np.nan)\n",
    "    \n",
    "    # Fill PAC values into source estimate\n",
    "    channels = np.concatenate((stc.vertices[0], stc.vertices[1]))\n",
    "    for i, channel in enumerate(channels):\n",
    "        if i in pac_results_clean.index:\n",
    "            pac_data[i] = pac_results_clean.loc[i][\"pac\"]\n",
    "    \n",
    "    pac_stc.data = pac_data\n",
    "    n_nans = np.isnan(pac_data).sum()\n",
    "    \n",
    "    if n_nans > 0:\n",
    "        print(f\"Warning: {n_nans} vertices without PAC values\")\n",
    "    \n",
    "    return pac_stc\n",
    "\n",
    "print(\"Data loading functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Data Loading\n",
    "\n",
    "Load source estimates and PAC results for all subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading data for all subjects...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stc_dict = {}\n",
    "pac_results_dict = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    print(f\"\\nProcessing subject {subject}...\")\n",
    "    \n",
    "    # Load data\n",
    "    stc, pac_results = load_subject_data(subject, event_types[0], data_dir, avs_dir)\n",
    "    \n",
    "    # Create PAC source estimate\n",
    "    pac_stc = create_pac_stc(stc, pac_results)\n",
    "    \n",
    "    stc_dict[subject] = pac_stc\n",
    "    pac_results_dict[subject] = pac_results\n",
    "\n",
    "print(f\"\\nData loading complete!\")\n",
    "print(f\"Source estimate shape: {stc_dict[1].data.shape}\")\n",
    "print(f\"Number of vertices: {len(stc_dict[1].vertices[0]) + len(stc_dict[1].vertices[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAC Distribution Analysis\n",
    "\n",
    "Visualise the distribution of PAC values before morphing to fsaverage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for subject in subjects:\n",
    "    pac_data = pac_results_dict[subject]\n",
    "    sns.stripplot(x=[subject]*len(pac_data), y=pac_data[\"pac\"], \n",
    "                 alpha=0.1, size=3, color='black')\n",
    "\n",
    "# Add significance thresholds\n",
    "plt.axhline(y=1.56, color=\"grey\", linestyle=\"--\", alpha=0.7, label=\"p < 0.05\")\n",
    "plt.axhline(y=1.96, color=\"darkgrey\", linestyle=\"--\", alpha=0.7, label=\"p < 0.01\") \n",
    "plt.axhline(y=2.56, color=\"lightgrey\", linestyle=\"--\", alpha=0.7, label=\"p < 0.001\")\n",
    "\n",
    "plt.xlabel(\"Subject\")\n",
    "plt.ylabel(\"PAC z-score\")\n",
    "plt.title(\"Distribution of PAC Values (Individual Subject Space)\")\n",
    "plt.ylim(-3, 20)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "all_pac_values = pd.concat([pac_results_dict[s][\"pac\"] for s in subjects])\n",
    "print(f\"\\nPAC Summary Statistics:\")\n",
    "print(f\"Mean: {all_pac_values.mean():.3f}\")\n",
    "print(f\"Std: {all_pac_values.std():.3f}\")\n",
    "print(f\"Range: {all_pac_values.min():.3f} to {all_pac_values.max():.3f}\")\n",
    "print(f\"Significant values (|z| > 1.65): {(np.abs(all_pac_values) > 1.65).sum()} / {len(all_pac_values)} ({(np.abs(all_pac_values) > 1.65).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphing to fsaverage Space\n",
    "\n",
    "Transform individual subject data to common fsaverage space for group analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Morphing individual data to fsaverage space...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "stcs_fsaverage = {}\n",
    "\n",
    "for subject in subjects:\n",
    "    print(f\"Morphing subject {subject} to fsaverage...\")\n",
    "    stc = stc_dict[subject]\n",
    "    \n",
    "    # Compute morphing and apply\n",
    "    morph = mne.compute_source_morph(\n",
    "        stc, \n",
    "        subject_from=f\"as{subject:02d}\", \n",
    "        subject_to='fsaverage', \n",
    "        subjects_dir=SUBJECTS_DIR\n",
    "    )\n",
    "    stc_fsaverage = morph.apply(stc)\n",
    "    stcs_fsaverage[subject] = stc_fsaverage\n",
    "\n",
    "print(\"Morphing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-Level Analysis\n",
    "\n",
    "Analyse PAC patterns across all subjects in fsaverage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Significance threshold\n",
    "threshold = 1.65\n",
    "\n",
    "# Collect all morphed data\n",
    "all_stcs = np.array([stc.data[:, 0] for stc in stcs_fsaverage.values()])\n",
    "print(f\"Group data shape: {all_stcs.shape}\")\n",
    "\n",
    "# Count significant values per vertex\n",
    "sig_count = np.sum(np.abs(all_stcs) > threshold, axis=0)\n",
    "\n",
    "# Create count and average source estimates\n",
    "sig_count_stc = list(stcs_fsaverage.values())[0].copy()\n",
    "average_stc = list(stcs_fsaverage.values())[0].copy()\n",
    "\n",
    "sig_count_stc.data = sig_count[:, np.newaxis]\n",
    "average_stc.data = np.nanmean(all_stcs, axis=0)[:, np.newaxis]\n",
    "\n",
    "# Report overlap statistics\n",
    "sig_vertices = sig_count[sig_count > 0]\n",
    "print(f\"\\nGroup-level PAC Results:\")\n",
    "print(f\"- Vertices with significant PAC: {len(sig_vertices)}\")\n",
    "print(f\"- Vertices with 2+ subjects: {np.sum(sig_count > 1)}\")\n",
    "print(f\"- Vertices with 3+ subjects: {np.sum(sig_count > 2)}\")\n",
    "print(f\"- Vertices with 4+ subjects: {np.sum(sig_count > 3)}\")\n",
    "print(f\"- Vertices with all 5 subjects: {np.sum(sig_count > 4)}\")\n",
    "\n",
    "# Plot histogram of overlap counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_counts, count_frequencies = np.unique(sig_count[sig_count > 0], return_counts=True)\n",
    "plt.bar(unique_counts, count_frequencies, alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Number of subjects with significant PAC')\n",
    "plt.ylabel('Number of vertices')\n",
    "plt.title('Overlap of Significant PAC Across Subjects')\n",
    "plt.xticks(unique_counts)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROI Analysis Setup\n",
    "\n",
    "Load anatomical labels and extract PAC values for each region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_roi_labels(subjects_dir, subject, compound_labels):\n",
    "    \"\"\"Load ROI labels for a subject.\"\"\"\n",
    "    labels_dict = {}\n",
    "    \n",
    "    for area in compound_labels.keys():\n",
    "        labels_dict[area] = {}\n",
    "        for hemi in [\"lh\", \"rh\"]:\n",
    "            labels_dict[area][hemi] = []\n",
    "            l_short = \"R\" if hemi == \"rh\" else \"L\"\n",
    "            \n",
    "            for roi in compound_labels[area]:\n",
    "                label_fname = os.path.join(subjects_dir, subject, \"label\", \n",
    "                                         f\"{hemi}.{l_short}_{roi}_ROI.label\")\n",
    "                \n",
    "                if os.path.exists(label_fname):\n",
    "                    label = mne.read_label(label_fname)\n",
    "                    labels_dict[area][hemi].append(label)\n",
    "                else:\n",
    "                    print(f\"Warning: Missing label {label_fname}\")\n",
    "    \n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def extract_pac_per_roi(stc_dict, labels_dict, compound_labels):\n",
    "    \"\"\"Extract PAC values per ROI for all subjects.\"\"\"\n",
    "    pac_per_label = pd.DataFrame()\n",
    "    \n",
    "    for subject in subjects:\n",
    "        stc = stc_dict[subject]\n",
    "        subject_labels = labels_dict[subject]\n",
    "        \n",
    "        for area, labels in subject_labels.items():\n",
    "            for hemi, labels_list in labels.items():\n",
    "                for label in labels_list:\n",
    "                    # Extract data from label\n",
    "                    stc_label = stc.in_label(label)\n",
    "                    data_label = stc_label.data[:, 0]\n",
    "                    \n",
    "                    # Create dataframe entries\n",
    "                    df_temp = pd.DataFrame({\n",
    "                        'PAC': data_label,\n",
    "                        'subject': subject,\n",
    "                        'area': area,\n",
    "                        'label': label.name,\n",
    "                        'hemi': hemi\n",
    "                    })\n",
    "                    \n",
    "                    pac_per_label = pd.concat([pac_per_label, df_temp], axis=0)\n",
    "    \n",
    "    return pac_per_label\n",
    "\n",
    "print(\"ROI analysis functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for all subjects\n",
    "print(\"Loading anatomical labels...\")\n",
    "labels_dict = {}\n",
    "for subject in subjects:\n",
    "    sub_name = f\"as{subject:02d}\"\n",
    "    labels_dict[subject] = load_roi_labels(SUBJECTS_DIR, sub_name, compound_labels)\n",
    "\n",
    "# Extract PAC values per ROI\n",
    "print(\"\\nExtracting PAC values per ROI...\")\n",
    "pac_per_label = extract_pac_per_roi(stc_dict, labels_dict, compound_labels)\n",
    "\n",
    "# Remove NaN values and exclude problematic ROIs\n",
    "pac_per_label = pac_per_label.dropna()\n",
    "pac_per_label = pac_per_label[pac_per_label[\"area\"] != \"EC\"]  # Exclude EC due to data issues\n",
    "\n",
    "print(f\"\\nROI analysis data shape: {pac_per_label.shape}\")\n",
    "print(f\"Areas analysed: {list(pac_per_label['area'].unique())}\")\n",
    "print(f\"\\nData points per area:\")\n",
    "print(pac_per_label.groupby('area').size().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Apply statistical tests to determine significance of PAC patterns across brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performing statistical analysis...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Convert PAC z-scores to p-values\n",
    "pac_per_label[\"p_value\"] = pac_per_label[\"PAC\"].transform(\n",
    "    lambda x: 2 * (1 - scipy.stats.norm.cdf(np.abs(x)))\n",
    ")\n",
    "\n",
    "# Apply FDR correction within each subject\n",
    "def apply_fdr_per_subject(group):\n",
    "    \"\"\"Apply FDR correction within a subject group.\"\"\"\n",
    "    _, fdr_p = mne.stats.fdr_correction(group[\"p_value\"], alpha=0.05)\n",
    "    return fdr_p\n",
    "\n",
    "pac_per_label[\"fdr_p_value\"] = pac_per_label.groupby(\"subject\")[\"p_value\"].transform(\n",
    "    lambda x: mne.stats.fdr_correction(x, alpha=0.05)[1]\n",
    ")\n",
    "\n",
    "# Significance thresholds\n",
    "p_threshold = 0.05\n",
    "threshold_z = 1.65\n",
    "\n",
    "# Calculate significance markers\n",
    "pac_per_label[\"significant\"] = pac_per_label[\"PAC\"] > threshold_z\n",
    "pac_per_label[\"significant_fdr\"] = pac_per_label[\"fdr_p_value\"] < p_threshold\n",
    "\n",
    "print(f\"Statistical summary:\")\n",
    "print(f\"- Mean p-value: {pac_per_label['p_value'].mean():.4f}\")\n",
    "print(f\"- Mean FDR-corrected p-value: {pac_per_label['fdr_p_value'].mean():.4f}\")\n",
    "print(f\"- Uncorrected significant: {pac_per_label['significant'].sum()} / {len(pac_per_label)} ({pac_per_label['significant'].mean()*100:.1f}%)\")\n",
    "print(f\"- FDR-corrected significant: {pac_per_label['significant_fdr'].sum()} / {len(pac_per_label)} ({pac_per_label['significant_fdr'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate fraction of significant sources per ROI\n",
    "sig_fraction = pac_per_label.groupby([\"area\", \"hemi\", \"subject\"]).agg({\n",
    "    \"significant_fdr\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Test each ROI against chance (5%)\n",
    "print(\"\\nTesting ROIs against chance level (5%):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "roi_tests = {}\n",
    "for area in sig_fraction['area'].unique():\n",
    "    area_data = sig_fraction[sig_fraction['area'] == area][\"significant_fdr\"]\n",
    "    t_stat, p_val = scipy.stats.ttest_1samp(area_data, 0.05, alternative='greater')\n",
    "roi_tests[area] = {'t_stat': t_stat, 'p_val': p_val, 'mean_frac': area_data.mean()}\n",
    "print(f\"{area}: t-stat = {t_stat:.3f}, p-value = {p_val:.4f}, mean fraction = {area_data.mean():.3f}\")\n",
    "# Convert to dataframe and apply FDR correction\n",
    "test_results = pd.DataFrame.from_dict(roi_tests, orient='index').reset_index()\n",
    "test_results.columns = ['area', 't_stat', 'p_val', 'mean_frac']\n",
    "test_results['fdr_p_val'] = mne.stats.fdr_correction(test_results['p_val'], alpha=0.05)[1]\n",
    "test_results['significant'] = test_results['fdr_p_val'] < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed-Effects Statistical Model\n",
    "\n",
    "Fit a mixed-effects model to account for between-subject variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for mixed-effects model\n",
    "order_pac = pac_per_label.groupby(\"area\")[\"PAC\"].mean().sort_values(ascending=True).index\n",
    "pac_per_label[\"area\"] = pd.Categorical(pac_per_label[\"area\"], categories=order_pac, ordered=True)\n",
    "\n",
    "print(\"Fitting mixed-effects model...\")\n",
    "print(\"Model: PAC ~ area + (1|subject)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Fit mixed-effects model with area as fixed effect and subject as random effect\n",
    "try:\n",
    "    model = smf.mixedlm(\"PAC ~ area\", data=pac_per_label, groups=pac_per_label[\"subject\"])\n",
    "    result = model.fit()\n",
    "    print(result.summary())\n",
    "    \n",
    "    # Extract and display key statistics\n",
    "    print(\"\\nModel Summary:\")\n",
    "    print(f\"- Number of observations: {result.nobs}\")\n",
    "    print(f\"- Number of groups (subjects): {result.n_groups}\")\n",
    "    print(f\"- Log-likelihood: {result.llf:.3f}\")\n",
    "    print(f\"- AIC: {result.aic:.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error fitting mixed-effects model: {e}\")\n",
    "    print(\"Proceeding with simpler analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation: Fraction of Significant Sources\n",
    "\n",
    "Plot the fraction of significant PAC sources per brain region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualisation of significant fraction per ROI\n",
    "order = sig_fraction.groupby(\"area\")[\"significant_fdr\"].mean().sort_values(ascending=True).index\n",
    "palette = sns.color_palette(\"magma\", n_colors=len(compound_labels.keys())+3)[2:-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(\n",
    "    data=sig_fraction, \n",
    "    x=\"area\", \n",
    "    y=\"significant_fdr\", \n",
    "    order=order, \n",
    "    palette=palette,\n",
    "    ci=95,\n",
    "    errcolor=\"grey\"\n",
    ")\n",
    "\n",
    "plt.axhline(y=0.05, color=\"grey\", linestyle=\"--\", alpha=0.7, label=\"Chance level (5%)\")\n",
    "plt.ylabel(f\"Fraction of significant sources\\n(p < {p_threshold}, FDR corrected)\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(loc=\"upper right\", frameon=False)\n",
    "plt.title(\"Phase-Amplitude Coupling by Brain Region\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fname = f\"pac_fraction_per_roi_{theta_freqs[0]}-{theta_freqs[1]}_{gamma_freqs[0]}-{gamma_freqs[1]}_{time_window[0]}-{time_window[1]}_fdr\"\n",
    "plt.savefig(fname + \".png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(fname + \".pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figure saved as: {fname}.png and {fname}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation: Mean PAC Values\n",
    "\n",
    "Plot the mean PAC z-scores by brain region and hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualisation of mean PAC values per ROI\n",
    "plt.figure(figsize=(12, 8))\n",
    "order_pac = pac_per_label.groupby(\"area\")[\"PAC\"].mean().sort_values(ascending=True).index\n",
    "palette_cb = sns.color_palette(\"colorblind\", n_colors=10)[1:-1]\n",
    "\n",
    "sns.barplot(\n",
    "    data=pac_per_label,\n",
    "    x=\"area\",\n",
    "    y=\"PAC\", \n",
    "    hue=\"hemi\",\n",
    "    order=order_pac,\n",
    "    palette=palette_cb,\n",
    "    ci=95,\n",
    "    errcolor=\"grey\"\n",
    ")\n",
    "\n",
    "plt.ylabel(\"Mean PAC z-score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title(\"Mean PAC Values by Brain Region and Hemisphere\")\n",
    "plt.legend(title=\"Hemisphere\", labels=[\"Left\", \"Right\"])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fname = f\"pac_values_per_roi_{theta_freqs[0]}-{theta_freqs[1]}_{gamma_freqs[0]}-{gamma_freqs[1]}_{time_window[0]}-{time_window[1]}\"\n",
    "plt.savefig(fname + \".png\", dpi=300, bbox_inches='tight')\n",
    "plt.savefig(fname + \".pdf\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figure saved as: {fname}.png and {fname}.pdf\")\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nMean PAC values by region:\")\n",
    "mean_pac_summary = pac_per_label.groupby(\"area\")[\"PAC\"].agg(['mean', 'std', 'count']).round(3)\n",
    "mean_pac_summary = mean_pac_summary.sort_values('mean', ascending=False)\n",
    "print(mean_pac_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Visualisation Functions\n",
    "\n",
    "Create functions for consistent brain plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_brain_results(stc, subjects_dir, save_name=None, colormap='magma', \n",
    "                      surface='pial', views='lateral'):\n",
    "    \"\"\"\n",
    "    Plot brain results with consistent parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    stc : mne.SourceEstimate\n",
    "        Source estimate to plot\n",
    "    subjects_dir : str\n",
    "        Path to subjects directory\n",
    "    save_name : str, optional\n",
    "        Filename to save (without extension)\n",
    "    colormap : str\n",
    "        Colormap to use\n",
    "    surface : str\n",
    "        Brain surface type\n",
    "    views : str\n",
    "        Brain view angle\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    brain : mne.viz.Brain\n",
    "        Brain plot object\n",
    "    \"\"\"\n",
    "    vmin, vmid, vmax = 1, 3, 5\n",
    "    \n",
    "    brain = stc.plot(\n",
    "        subjects_dir=subjects_dir,\n",
    "        initial_time=0,\n",
    "        hemi='split',\n",
    "        time_viewer=False,\n",
    "        colorbar=True,\n",
    "        colormap=colormap,\n",
    "        size=(900, 450),\n",
    "        clim=dict(kind='value', lims=[vmin, vmid, vmax]),\n",
    "        smoothing_steps=2,\n",
    "        transparent=False,\n",
    "        surface=surface,\n",
    "        background=\"white\",\n",
    "        views=views\n",
    "    )\n",
    "    \n",
    "    if save_name:\n",
    "        brain.save_image(f\"{save_name}.png\")\n",
    "        print(f\"Brain plot saved as: {save_name}.png\")\n",
    "    \n",
    "    return brain\n",
    "\n",
    "\n",
    "def create_colorbar(vmin, vmid, vmax, colormap='magma', orientation='horizontal'):\n",
    "    \"\"\"\n",
    "    Create a standalone colorbar for brain plots.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5.5, 3.4))\n",
    "    \n",
    "    mne.viz.plot_brain_colorbar(\n",
    "        ax, \n",
    "        clim=dict(kind=\"value\", lims=[vmin, vmid, vmax]), \n",
    "        colormap=colormap, \n",
    "        transparent=False, \n",
    "        orientation=orientation\n",
    "    )\n",
    "    \n",
    "    # Customise colorbar\n",
    "    x = np.linspace(vmin, vmax, 3)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f\"{i:.1f}\" for i in x])\n",
    "    ax.set_xlabel(\"PAC z-score\")\n",
    "    ax.tick_params(tick1On=False)\n",
    "    \n",
    "    fig.set_dpi(300)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "print(\"Brain visualisation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brain Visualisation: Average PAC\n",
    "\n",
    "Plot the average PAC across all subjects on the brain surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average PAC across all subjects\n",
    "print(\"Creating brain visualisation...\")\n",
    "\n",
    "# Generate multiple views\n",
    "views = ['lateral', 'medial']\n",
    "surfaces = ['pial', 'inflated']\n",
    "\n",
    "try:\n",
    "    for surface in surfaces:\n",
    "        for view in views:\n",
    "            save_name = f\"pac_average_{event_types[0]}_{theta_freqs[0]}-{theta_freqs[1]}_{gamma_freqs[0]}-{gamma_freqs[1]}_{surface}_{view}\"\n",
    "            \n",
    "            brain = plot_brain_results(\n",
    "                average_stc, \n",
    "                SUBJECTS_DIR, \n",
    "                save_name=save_name,\n",
    "                surface=surface,\n",
    "                views=view\n",
    "            )\n",
    "            \n",
    "            # Close brain to save memory\n",
    "            brain.close()\n",
    "    \n",
    "    print(\"Brain plots created for all surface/view combinations.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating brain plots: {e}\")\n",
    "    print(\"Brain visualisation requires proper MNE setup and subjects directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Standalone Colorbar\n",
    "\n",
    "Generate a colorbar for use in figures and presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create colorbar\n",
    "vmin, vmid, vmax = 1, 3, 5\n",
    "try:\n",
    "    fig, ax = create_colorbar(vmin, vmid, vmax)\n",
    "    \n",
    "    # Save colorbar\n",
    "    colorbar_name = f\"colorbar_vmin_{vmin}_vmid_{vmid}_vmax_{vmax}\"\n",
    "    fig.savefig(f\"{colorbar_name}.png\", transparent=True, dpi=300, bbox_inches='tight')\n",
    "    fig.savefig(f\"{colorbar_name}.pdf\", transparent=True, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Colorbar saved as: {colorbar_name}.png and {colorbar_name}.pdf\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating colorbar: {e}\")\n",
    "    print(\"Creating simple colorbar instead...\")\n",
    "    \n",
    "    # Simple colorbar creation\n",
    "    fig, ax = plt.subplots(figsize=(6, 1))\n",
    "    cmap = plt.cm.magma\n",
    "    norm = plt.Normalize(vmin=vmin, vmax=vmax)\n",
    "    cbar = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "                       cax=ax, orientation='horizontal')\n",
    "    cbar.set_label('PAC z-score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
